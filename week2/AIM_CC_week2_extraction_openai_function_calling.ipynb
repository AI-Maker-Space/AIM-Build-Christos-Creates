{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2def22ea",
      "metadata": {
        "id": "2def22ea"
      },
      "source": [
        "# Extraction with OpenAI Tools\n",
        "\n",
        "Performing extraction has never been easier! OpenAI's tool calling ability is the perfect thing to use as it allows for extracting multiple different elements from text that are different types.\n",
        "\n",
        "Models after 1106 use tools and support \"parallel function calling\" which makes this super easy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai --upgrade --quiet"
      ],
      "metadata": {
        "id": "QhQqeRxDvoAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d7aa87-4441-4e24-d5d1-17ebde10466f"
      },
      "id": "QhQqeRxDvoAo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "gj2PBDIXvy9X"
      },
      "id": "gj2PBDIXvy9X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c628496",
      "metadata": {
        "id": "5c628496"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.pydantic_v1 import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe9657b",
      "metadata": {
        "id": "afe9657b"
      },
      "outputs": [],
      "source": [
        "# Make sure to use a recent model that supports tools\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc0ca3b6",
      "metadata": {
        "id": "bc0ca3b6"
      },
      "outputs": [],
      "source": [
        "# Pydantic is an easy way to define a schema\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about people to extract.\"\"\"\n",
        "\n",
        "    name: str\n",
        "    age: Optional[int] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2036af68",
      "metadata": {
        "id": "2036af68"
      },
      "outputs": [],
      "source": [
        "chain = create_extraction_chain_pydantic(Person, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1748ad21",
      "metadata": {
        "id": "1748ad21",
        "outputId": "81c5afbe-510b-4de0-9859-577ee2a5875d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Person(name='jane', age=2), Person(name='bob', age=3)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"jane is 2 and bob is 3\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8262ce5",
      "metadata": {
        "id": "c8262ce5"
      },
      "outputs": [],
      "source": [
        "# Let's define another element\n",
        "class Class(BaseModel):\n",
        "    \"\"\"Information about classes to extract.\"\"\"\n",
        "\n",
        "    teacher: str\n",
        "    students: List[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4973c104",
      "metadata": {
        "id": "4973c104"
      },
      "outputs": [],
      "source": [
        "chain = create_extraction_chain_pydantic([Person, Class], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e976a15e",
      "metadata": {
        "id": "e976a15e",
        "outputId": "d7e4ba95-e1fe-4471-8385-6780d8cde89d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Person(name='jane', age=2),\n",
              " Person(name='bob', age=3),\n",
              " Class(teacher='Mrs Sampson', students=['jane', 'bob'])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"jane is 2 and bob is 3 and they are in Mrs Sampson's class\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. San Francisco 49ers Wikipedia Doc"
      ],
      "metadata": {
        "id": "P5-e9ydxyhpI"
      },
      "id": "P5-e9ydxyhpI"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wikipedia --quiet"
      ],
      "metadata": {
        "id": "KycclpKkw8vM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36940cc-6a4a-421b-95db-d9c1cbdaf7ac"
      },
      "id": "KycclpKkw8vM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load a wikipedia page into txt file to pass to chain\n",
        "from langchain.document_loaders import WikipediaLoader\n",
        "\n",
        "docs = WikipediaLoader(query=\"San Francisco 49ers\", load_max_docs=2).load()\n",
        "docs[0].page_content[:49]"
      ],
      "metadata": {
        "id": "ys1KXhxgwptD",
        "outputId": "52b553d2-d16b-457d-f449-4a3ab00e44d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "ys1KXhxgwptD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The San Francisco 49ers (also written as the San '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs[0].page_content)"
      ],
      "metadata": {
        "id": "oXFg74VhySeq",
        "outputId": "a1d3be54-e0ee-47ce-d894-15985ef11211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oXFg74VhySeq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1].page_content[:49]"
      ],
      "metadata": {
        "id": "xuL1kKKLxgPb",
        "outputId": "18e4b9ae-d0cf-4e7b-eb32-02f706aa0ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "xuL1kKKLxgPb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The 2022 season was the San Francisco 49ers' 73rd\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": docs[0].page_content})"
      ],
      "metadata": {
        "id": "ERWJBtDux27E",
        "outputId": "80a48a83-2c35-46dd-fbd8-b284c7a0a86f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ERWJBtDux27E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Person(name='Tony Morabito', age=47),\n",
              " Person(name='Victor Morabito', age=45),\n",
              " Class(teacher='Buck Shaw', students=['Frankie Albert', 'Dicky Moegle'])]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6575a7d6",
      "metadata": {
        "id": "6575a7d6"
      },
      "source": [
        "## Under the hood\n",
        "\n",
        "Under the hood, this is a simple chain:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ba83e5",
      "metadata": {
        "id": "b8ba83e5"
      },
      "source": [
        "```python\n",
        "from typing import Union, List, Type, Optional\n",
        "\n",
        "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_tool\n",
        "from langchain.schema.runnable import Runnable\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.messages import SystemMessage\n",
        "from langchain.schema.language_model import BaseLanguageModel\n",
        "\n",
        "_EXTRACTION_TEMPLATE = \"\"\"Extract and save the relevant entities mentioned \\\n",
        "in the following passage together with their properties.\n",
        "\n",
        "If a property is not present and is not required in the function parameters, do not include it in the output.\"\"\"  # noqa: E501\n",
        "\n",
        "\n",
        "def create_extraction_chain_pydantic(\n",
        "    pydantic_schemas: Union[List[Type[BaseModel]], Type[BaseModel]],\n",
        "    llm: BaseLanguageModel,\n",
        "    system_message: str = _EXTRACTION_TEMPLATE,\n",
        ") -> Runnable:\n",
        "    if not isinstance(pydantic_schemas, list):\n",
        "        pydantic_schemas = [pydantic_schemas]\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_message),\n",
        "        (\"user\", \"{input}\")\n",
        "    ])\n",
        "    tools = [convert_pydantic_to_openai_tool(p) for p in pydantic_schemas]\n",
        "    model = llm.bind(tools=tools)\n",
        "    chain = prompt | model | PydanticToolsParser(tools=pydantic_schemas)\n",
        "    return chain\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create an extraction chain for american football data\n",
        "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
        "\n",
        "sf49ers2023 = WikipediaLoader(query=\"2023_San_Francisco_49ers_season\", load_max_docs=2).load()\n",
        "\n",
        "class GameSummaries(BaseModel):\n",
        "    \"\"\"Information about each week's game.\"\"\"\n",
        "\n",
        "    week: str\n",
        "    opponent: str\n",
        "    result: Optional[str] = None\n",
        "    date: Optional[str] = None\n",
        "    time: Optional[str] = None\n",
        "    weather: Optional[str] = None\n",
        "    attendance: Optional[int] = None\n",
        "\n",
        "niner_players = create_extraction_chain_pydantic(GameSummaries, model)\n",
        "\n",
        "extracted_summaries = []\n",
        "for i in range(len(sf49ers2023)):\n",
        "    try:\n",
        "        extracted_summaries.append(\n",
        "            niner_players.invoke({\"input\": sf49ers2023[i].page_content})\n",
        "        )\n",
        "    except:\n",
        "        print(f\"Skipping {i}\")\n",
        "        continue\n",
        "extracted_summaries"
      ],
      "metadata": {
        "id": "tod7HJe1ytuv",
        "outputId": "3658c3ba-55de-4886-ec23-36686d6579e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tod7HJe1ytuv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[GameSummaries(week='1', opponent='Pittsburgh Steelers', result=None, date=None, time=None, weather=None, attendance=None)],\n",
              " [GameSummaries(week='16', opponent='Washington Commanders', result='win', date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='15', opponent='Seattle Seahawks', result='win', date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='14', opponent='Tampa Bay Buccaneers', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='13', opponent='Miami Dolphins', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='12', opponent='New Orleans Saints', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='11', opponent='Arizona Cardinals', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='10', opponent='Los Angeles Chargers', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='8', opponent='Los Angeles Rams', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='7', opponent='Kansas City Chiefs', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='6', opponent='Atlanta Falcons', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='5', opponent='Carolina Panthers', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='4', opponent='Los Angeles Rams', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='3', opponent='Denver Broncos', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='2', opponent='Seattle Seahawks', result=None, date=None, time=None, weather=None, attendance=None),\n",
              "  GameSummaries(week='1', opponent='Chicago Bears', result=None, date=None, time=None, weather=None, attendance=None)]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's only able to get week and opponent for 2023 byt it is able to grab the result from last year's (2022) week 16 matchup. As of 12/5/23 only week 1 through 13 has occured."
      ],
      "metadata": {
        "id": "mndUTB1d75KL"
      },
      "id": "mndUTB1d75KL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ZJiX7nUrOZL-"
      },
      "id": "ZJiX7nUrOZL-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Music Data Extraction Example"
      ],
      "metadata": {
        "id": "vuvcWuTJObVd"
      },
      "id": "vuvcWuTJObVd"
    },
    {
      "cell_type": "code",
      "source": [
        "# sample data creation\n",
        "import pandas as pd\n",
        "\n",
        "# Creating the data for the table\n",
        "data = {\n",
        "    \"Artist\": [\"Tame Impala\"] * 25,\n",
        "    \"Album\": [\"Currents\"] * 13 + [\"The Slow Rush\"] * 12,\n",
        "    \"Song\": [\"Let It Happen\", \"Nangs\", \"The Moment\", \"Yes Im Changing\", \"Eventually\", \"Gossip\", \"The Less I Know the Better\", \"Past Life\", \"Disciples\", \"Cause Im a Man\", \"Reality in Motion\", \"Love/Paranoia\", \"New Person, Same Old Mistakes\"]\n",
        "    + [\"One More Year\", \"Instant Destiny\", \"Borderline\", \"Posthumous Forgiveness\", \"Breathe Deeper\", \"Tomorrows Dust\", \"On Track\", \"Lost in Yesterday\", \"Is It True\", \"It Might Be Time\", \"Glimmer\", \"One More Hour\"]\n",
        "}\n",
        "\n",
        "# Creating the pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# df to text file\n",
        "df_str = df.to_string()\n",
        "print(df_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fzdWPl91KIS",
        "outputId": "c002b4fd-6e87-4e1d-ce80-959d806471e7"
      },
      "id": "1fzdWPl91KIS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Artist          Album                           Song\n",
            "0   Tame Impala       Currents                  Let It Happen\n",
            "1   Tame Impala       Currents                          Nangs\n",
            "2   Tame Impala       Currents                     The Moment\n",
            "3   Tame Impala       Currents                Yes Im Changing\n",
            "4   Tame Impala       Currents                     Eventually\n",
            "5   Tame Impala       Currents                         Gossip\n",
            "6   Tame Impala       Currents     The Less I Know the Better\n",
            "7   Tame Impala       Currents                      Past Life\n",
            "8   Tame Impala       Currents                      Disciples\n",
            "9   Tame Impala       Currents                 Cause Im a Man\n",
            "10  Tame Impala       Currents              Reality in Motion\n",
            "11  Tame Impala       Currents                  Love/Paranoia\n",
            "12  Tame Impala       Currents  New Person, Same Old Mistakes\n",
            "13  Tame Impala  The Slow Rush                  One More Year\n",
            "14  Tame Impala  The Slow Rush                Instant Destiny\n",
            "15  Tame Impala  The Slow Rush                     Borderline\n",
            "16  Tame Impala  The Slow Rush         Posthumous Forgiveness\n",
            "17  Tame Impala  The Slow Rush                 Breathe Deeper\n",
            "18  Tame Impala  The Slow Rush                 Tomorrows Dust\n",
            "19  Tame Impala  The Slow Rush                       On Track\n",
            "20  Tame Impala  The Slow Rush              Lost in Yesterday\n",
            "21  Tame Impala  The Slow Rush                     Is It True\n",
            "22  Tame Impala  The Slow Rush               It Might Be Time\n",
            "23  Tame Impala  The Slow Rush                        Glimmer\n",
            "24  Tame Impala  The Slow Rush                  One More Hour\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "import json\n",
        "\n",
        "# musical system message\n",
        "musical_system_message = \"\"\"A text document will be passed to you. Extract from it all musical information about the artist, album and songs that are mentioned in this document.\n",
        "Do not extract the name of the article itself. If no artist, album or songs are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
        "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
        "\n",
        "# musical system message\n",
        "musical_prompt = ChatPromptTemplate.from_messages([(\"system\", musical_system_message), (\"human\", \"{input}\")])\n",
        "musical_prompt\n",
        "\n",
        "# Function output schema\n",
        "class Album(BaseModel):\n",
        "    \"\"\"Information about musical album.\"\"\"\n",
        "\n",
        "    album_name: str = Field(description=\"album name\")\n",
        "    album_songs: List[str] = Field(description=\"songs\")\n",
        "\n",
        "class Artist(BaseModel):\n",
        "    \"\"\"Information about musical artist.\"\"\"\n",
        "\n",
        "    artist_name: str = Field(description=\"artist name\")\n",
        "    albums: Optional[List[Album]] = Field(description=\"albums\")\n",
        "\n",
        "\n",
        "# Make sure to use a recent model that supports tools\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
        "\n",
        "# Function definition\n",
        "function = [convert_pydantic_to_openai_function(Artist)]\n",
        "chain = (\n",
        "    musical_prompt\n",
        "    | model.bind(functions=function, function_call={\"name\": \"Artist\"})\n",
        "    | (\n",
        "        lambda x: json.loads(x.additional_kwargs[\"function_call\"][\"arguments\"])\n",
        "    )\n",
        ")\n",
        "\n",
        "extracted_response = chain.invoke({\"input\": df_str})"
      ],
      "metadata": {
        "id": "lVZvhGsh8TE-"
      },
      "id": "lVZvhGsh8TE-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3k3ILDc9mk3",
        "outputId": "ba8b42ae-6051-448e-afcc-af5b87cd6131"
      },
      "id": "e3k3ILDc9mk3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'artist_name': 'Tame Impala',\n",
              " 'albums': [{'album_name': 'Currents',\n",
              "   'album_songs': ['Let It Happen',\n",
              "    'Nangs',\n",
              "    'The Moment',\n",
              "    'Yes Im Changing',\n",
              "    'Eventually',\n",
              "    'Gossip',\n",
              "    'The Less I Know the Better',\n",
              "    'Past Life',\n",
              "    'Disciples',\n",
              "    'Cause Im a Man',\n",
              "    'Reality in Motion',\n",
              "    'Love/Paranoia',\n",
              "    'New Person, Same Old Mistakes']},\n",
              "  {'album_name': 'The Slow Rush',\n",
              "   'album_songs': ['One More Year',\n",
              "    'Instant Destiny',\n",
              "    'Borderline',\n",
              "    'Posthumous Forgiveness',\n",
              "    'Breathe Deeper',\n",
              "    'Tomorrows Dust',\n",
              "    'On Track',\n",
              "    'Lost in Yesterday',\n",
              "    'Is It True',\n",
              "    'It Might Be Time',\n",
              "    'Glimmer',\n",
              "    'One More Hour']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}